from typing import Dict, Any, Optional
import logging
import json
from pathlib import Path

from .router import route
from .state import get_state, set_state, set_fuzzy_last
from ..response.formatters import html_paragraphs, system_note

logger = logging.getLogger("chatbot")

# ===================== LLM (optional) =====================
LLM_READY = False
TPL = ""

try:
    from chatbot.services.llm.client import ollama_chat, build_prompt  # báº¡n tá»± implement
    TPL = Path("chatbot/services/llm/prompts/chat_response.md").read_text(encoding="utf-8")
    LLM_READY = True
except Exception:
    LLM_READY = False
    logger.exception("LLM prompt/client not ready (will fallback to static replies)")

# ===================== LOOKUP =====================
try:
    from lookup.services.tool.lookup_by_name import lookup_tool_by_name
    from lookup.services.tool.similar_by_code import similar_tool_by_code
    from lookup.services.holder.lookup_by_name import lookup_holder_by_name
    from lookup.services.holder.similar_by_code import similar_holder_by_code
    LOOKUP_READY = True
except Exception:
    LOOKUP_READY = False
    logger.exception("LOOKUP import failed")

# ===================== FUZZY =====================
try:
    from fuzzy_reco.services.tool.engine import score_tool_candidates
    from fuzzy_reco.services.holder.engine import score_holder_candidates
    FUZZY_READY = True
except Exception:
    FUZZY_READY = False
    logger.exception("FUZZY import failed")


def _looks_like_code_only(msg: str) -> bool:
    s = (msg or "").strip()
    return (len(s) >= 6) and (" " not in s)


def handle_message(request, message: str, ctx: Dict[str, Any]) -> Dict[str, Any]:
    """
    ctx: { model, explain_fuzzy, request_id }
    return: { reply: "<html...>" }
    """
    rid = ctx.get("request_id", "noid")
    state = get_state(request)

    r = route(message, state_domain=state.get("domain"))
    domain = r.get("domain") or None
    intent = r.get("intent")

    logger.debug(f"[{rid}] ROUTE_RESULT intent={intent} domain={domain} state_domain={state.get('domain')}")
    logger.debug(f"[{rid}] READY lookup={LOOKUP_READY} fuzzy={FUZZY_READY} llm={LLM_READY}")

    # Escape hatch: mÃ£ hÃ ng thÃ¬ LOOKUP luÃ´n
    if _looks_like_code_only(message) and intent == "CHAT":
        intent = "LOOKUP"
        logger.debug(f"[{rid}] ESCAPE_HATCH: force intent=LOOKUP for code-like input")

    if domain:
        set_state(request, domain=domain)

    if intent == "LOOKUP":
        return _handle_lookup(request, message, domain, ctx, rid)

    if intent == "FUZZY":
        if not domain:
            set_state(request, pending_intent="FUZZY", missing_fields=["domain"])
            return {
                "reply": html_paragraphs([
                    "Ok ğŸ˜„ Báº¡n muá»‘n mÃ¬nh <b>Ä‘á» xuáº¥t fuzzy</b> cho <b>Tool</b> hay <b>Holder</b>?",
                    "â€¢ <b>Tool</b> (dao, mÅ©i khoan, taro...)",
                    "â€¢ <b>Holder</b> (báº§u káº¹p, chuáº©n gÃ¡, collet...)",
                    system_note("Gá»£i Ã½: gÃµ 'tool: ...' hoáº·c 'holder: ...' Ä‘á»ƒ mÃ¬nh hiá»ƒu ngay."),
                ])
            }
        return _handle_fuzzy(request, message, domain, ctx, rid)

    # CHAT fallback (thÃ¢n thiá»‡n)
    return {
        "reply": html_paragraphs([
            "ChÃ o báº¡n ğŸ‘‹ MÃ¬nh lÃ  trá»£ lÃ½ kho cÃ´ng cá»¥ TMS.",
            "Báº¡n muá»‘n <b>tra cá»©u</b> hay <b>Ä‘á» xuáº¥t</b> theo nhu cáº§u?",
            "",
            "ğŸ” <b>Tra cá»©u</b>: gá»­i <b>mÃ£</b> hoáº·c <b>tÃªn</b> (vd: <b>SER8350A0B11</b>, <b>EM12-...</b>)",
            "âœ¨ <b>Äá» xuáº¥t fuzzy</b>: (vd: <b>tool: khÃ¡ ráº» nhÆ°ng cáº§n bá»n</b> / <b>holder: Æ°u tiÃªn chÃ­nh xÃ¡c, Ä‘á»™ Ä‘áº£o tháº¥p</b>)",
            system_note("Tip: Báº¡n khÃ´ng cáº§n gÃµ 'lÃ  gÃ¬', chá»‰ gá»­i mÃ£ thÃ´i cÅ©ng Ä‘Æ°á»£c."),
        ])
    }


def _handle_lookup(request, message: str, domain: Optional[str], ctx: Dict[str, Any], rid: str) -> Dict[str, Any]:
    if not LOOKUP_READY:
        logger.debug(f"[{rid}] LOOKUP not ready -> stub reply")
        return {
            "reply": html_paragraphs([
                "<b>Lookup</b> Ä‘ang á»Ÿ cháº¿ Ä‘á»™ stub (chÆ°a viáº¿t app lookup).",
                system_note("Báº¡n Ä‘Ã£ táº¡o app lookup rá»“i, náº¿u váº«n tháº¥y dÃ²ng nÃ y => import path Ä‘ang sai."),
            ])
        }

    text = (message or "").strip()
    lower = text.lower()
    want_similar = ("tÆ°Æ¡ng tá»±" in lower) or ("similar" in lower)

    logger.debug(f"[{rid}] LOOKUP start domain={domain} want_similar={want_similar} text='{text}'")

    def run_tool():
        return similar_tool_by_code(text) if want_similar else lookup_tool_by_name(text)

    def run_holder():
        return similar_holder_by_code(text) if want_similar else lookup_holder_by_name(text)

    # domain rÃµ -> cháº¡y Ä‘Ãºng
# domain rÃµ -> cháº¡y Ä‘Ãºng (nhÆ°ng cÃ³ fallback khi Ä‘oÃ¡n nháº§m)
    if domain == "tool":
        data = run_tool()
        logger.debug(f"[{rid}] LOOKUP tool found={data.get('found')} query={data.get('query')}")
        if data.get("found"):
            return _render_lookup_with_llm(data, ctx, rid)

        # FALLBACK: tool khÃ´ng tháº¥y -> thá»­ holder
        data2 = run_holder()
        logger.debug(f"[{rid}] LOOKUP fallback holder found={data2.get('found')} query={data2.get('query')}")
        if data2.get("found"):
            set_state(request, domain="holder")  # cáº­p nháº­t state cho láº§n sau
            return _render_lookup_with_llm(data2, ctx, rid)

        return _render_lookup_with_llm(data, ctx, rid)  # hoáº·c tráº£ not found chung


    if domain == "holder":
        data = run_holder()
        logger.debug(f"[{rid}] LOOKUP holder found={data.get('found')} query={data.get('query')}")
        if data.get("found"):
            return _render_lookup_with_llm(data, ctx, rid)

        # FALLBACK: holder khÃ´ng tháº¥y -> thá»­ tool
        data2 = run_tool()
        logger.debug(f"[{rid}] LOOKUP fallback tool found={data2.get('found')} query={data2.get('query')}")
        if data2.get("found"):
            set_state(request, domain="tool")
            return _render_lookup_with_llm(data2, ctx, rid)

        return _render_lookup_with_llm(data, ctx, rid)

    # domain chÆ°a rÃµ -> thá»­ tool rá»“i holder
    data1 = run_tool()
    logger.debug(f"[{rid}] LOOKUP auto tool found={data1.get('found')} query={data1.get('query')}")
    if data1.get("found"):
        set_state(request, domain="tool")
        return _render_lookup_with_llm(data1, ctx, rid)

    data2 = run_holder()
    logger.debug(f"[{rid}] LOOKUP auto holder found={data2.get('found')} query={data2.get('query')}")
    if data2.get("found"):
        set_state(request, domain="holder")
        return _render_lookup_with_llm(data2, ctx, rid)

    return {
        "reply": html_paragraphs([
            "MÃ¬nh chÆ°a tÃ¬m tháº¥y mÃ£/tÃªn nÃ y trong <b>Tool</b> vÃ  <b>Holder</b> ğŸ˜…",
            "Báº¡n thá»­ giÃºp mÃ¬nh 1 trong cÃ¡c cÃ¡ch sau nhÃ©:",
            "â€¢ Gá»­i láº¡i <b>mÃ£ chÃ­nh xÃ¡c</b> (khÃ´ng thá»«a kÃ½ tá»±)",
            "â€¢ Hoáº·c thÃªm tiá»n tá»‘: <b>tool: ...</b> / <b>holder: ...</b>",
            "â€¢ Hoáº·c gÃµ: <b>... tÆ°Æ¡ng tá»±</b> Ä‘á»ƒ mÃ¬nh tÃ¬m mÃ£ gáº§n giá»‘ng",
            system_note("VÃ­ dá»¥: 'tool: EM12-ABC' hoáº·c 'holder: BT40-...'"),
        ])
    }

def normalize_lookup_text(text: str) -> str:
    """
    Giá»¯ nguyÃªn ná»™i dung, chá»‰ chuáº©n hoÃ¡ xuá»‘ng dÃ²ng cho dá»… Ä‘á»c
    """
    if not text:
        return ""

    t = text

    # 1. Chuáº©n hoÃ¡ dáº¥u phÃ¢n cÃ¡ch
    t = t.replace(" | ", "\n")
    t = t.replace("| ", "\n")
    t = t.replace(" |", "\n")

    # 2. Gom cÃ¡c dÃ²ng, bá» dÃ²ng rá»—ng
    lines = []
    for line in t.splitlines():
        line = line.strip()
        if line:
            lines.append(line)

    # 3. Tráº£ vá» HTML-friendly
    return "<br>".join(lines)

def _render_lookup_with_llm(data: dict, ctx: Dict[str, Any], rid: str) -> Dict[str, Any]:
    """
    data: JSON tá»« lookup app (found, reply, item, similar...)
    - Náº¿u LLM ready: dÃ¹ng prompt Ä‘á»ƒ LLM nÃ³i láº¡i thÃ¢n thiá»‡n
    - Náº¿u khÃ´ng: fallback data['reply']
    """
    if not data.get("found"):
        # khÃ´ng cáº§n LLM cho not found (hoáº·c cÃ³ thá»ƒ dÃ¹ng cÅ©ng Ä‘Æ°á»£c)
        return {
            "reply": html_paragraphs([
                data.get("reply", "MÃ¬nh chÆ°a tÃ¬m tháº¥y."),
                system_note("Báº¡n cÃ³ thá»ƒ thá»­: nháº­p Ä‘Ãºng mÃ£ hÆ¡n, hoáº·c thÃªm 'tÆ°Æ¡ng tá»±'."),
            ])
        }

    base_reply = normalize_lookup_text(data.get("reply", "OK"))


    if not LLM_READY:
        return {"reply": base_reply}

    try:
        prompt = build_prompt(
            TPL,
            user_message=str(ctx.get("user_message", "")) or "",
            mode="LOOKUP",
            domain=str(ctx.get("domain_override") or "unknown"),
            explain_fuzzy="0",
            payload_json=json.dumps(data, ensure_ascii=False),
        )
        model = (ctx.get("model") or "gemma3:4b").strip()
        ai_reply = ollama_chat(model, prompt)
        logger.debug(f"[{rid}] LLM lookup reply_len={len(ai_reply or '')}")
        return {"reply": ai_reply or base_reply}
    except Exception:
        logger.exception(f"[{rid}] LLM lookup failed -> fallback static")
        return {"reply": base_reply}


def _handle_fuzzy(request, message: str, domain: str, ctx: Dict[str, Any], rid: str) -> Dict[str, Any]:
    model = ctx.get("model")
    explain_fuzzy = bool(ctx.get("explain_fuzzy"))

    logger.debug(f"[{rid}] FUZZY start domain={domain} model={model} explain={explain_fuzzy}")

    parse = _stub_parse_to_scores(message, domain)
    logger.debug(f"[{rid}] FUZZY parse_status={parse.get('status')} inputs={parse.get('inputs')}")

    if parse["status"] == "need_more_info":
        set_state(request, pending_intent="FUZZY", missing_fields=parse.get("missing_fields", []))
        return {"reply": parse["clarifying_question"]}

    if FUZZY_READY:
        fuzzy_out = score_tool_candidates(parse["inputs"]) if domain == "tool" else score_holder_candidates(parse["inputs"])
        logger.debug(f"[{rid}] FUZZY engine={fuzzy_out.get('engine_version')}")
    else:
        fuzzy_out = _demo_fuzzy_score(parse["inputs"], domain)
        logger.debug(f"[{rid}] FUZZY fallback demo")

    top3 = (fuzzy_out.get("ranked") or [])[:3]
    logger.debug(f"[{rid}] FUZZY top3={[(x.get('code'), x.get('score')) for x in top3]}")
    logger.debug(f"[{rid}] FUZZY rules={fuzzy_out.get('rules_fired')}")

    payload = {"parse": parse, "fuzzy": fuzzy_out}

    set_fuzzy_last(request, {
        "domain": domain,
        "model": model,
        "explain_fuzzy": explain_fuzzy,
        "parse": parse,
        "fuzzy": fuzzy_out,
    })

    # Náº¿u cÃ³ LLM thÃ¬ Ä‘á»ƒ LLM giáº£i thÃ­ch cho mÆ°á»£t
    if LLM_READY:
        try:
            prompt = build_prompt(
                TPL,
                user_message=message,
                mode="FUZZY",
                domain=domain,
                explain_fuzzy="1" if explain_fuzzy else "0",
                payload_json=json.dumps(payload, ensure_ascii=False),
            )
            ai_reply = ollama_chat(model, prompt)
            logger.debug(f"[{rid}] LLM fuzzy reply_len={len(ai_reply or '')}")
            if ai_reply:
                return {"reply": ai_reply}
        except Exception:
            logger.exception(f"[{rid}] LLM fuzzy failed -> fallback static")

    # fallback static
    reply_lines = [
        f"Ok, mÃ¬nh Ä‘Ã£ cháº¡y fuzzy cho <b>{domain.upper()}</b> âœ…",
        "",
        "ğŸ›ï¸ <b>Nhu cáº§u báº¡n nÃ³i:</b>",
        f"â€¢ Má»©c giÃ¡: <b>{parse['inputs']['cost_level']}/10</b>",
        f"â€¢ Æ¯u tiÃªn: bá»n <b>{parse['inputs'].get('durability_importance')}</b>/10, "
        f"chÃ­nh xÃ¡c <b>{parse['inputs'].get('precision_importance')}</b>/10, "
        f"tá»‘c Ä‘á»™ <b>{parse['inputs'].get('speed_importance')}</b>/10",
        "",
        system_note("Báº¥m icon ğŸ“ˆ Ä‘á»ƒ xem JSON fuzzy gáº§n nháº¥t (debug)."),
    ]
    return {"reply": html_paragraphs(reply_lines)}


# ===================== Stub parse & demo =====================
def _stub_parse_to_scores(text: str, domain: str) -> Dict[str, Any]:
    t = text.lower()

    if "khÃ¡ ráº»" in t or ("ráº»" in t and "Ä‘áº¯t" not in t):
        cost = 3
    elif "táº§m trung" in t or "trung bÃ¬nh" in t:
        cost = 5
    elif "Ä‘áº¯t" in t or "cao cáº¥p" in t or "xá»‹n" in t:
        cost = 8
    else:
        cost = None

    precision = 8 if ("chÃ­nh xÃ¡c" in t or "Ä‘á»™ Ä‘áº£o" in t or "runout" in t) else 5
    durability = 8 if ("bá»n" in t or "tuá»•i thá»" in t) else 5
    speed = 7 if ("tá»‘c" in t or "nhanh" in t) else 4

    if cost is None:
        return {
            "status": "need_more_info",
            "missing_fields": ["cost_level"],
            "clarifying_question": html_paragraphs([
                "Báº¡n muá»‘n má»©c giÃ¡ nÃ o?",
                "â€¢ <b>Ráº»</b> (khÃ¡ ráº»)  â€¢ <b>Táº§m trung</b>  â€¢ <b>Cao cáº¥p</b> (Ä‘áº¯t/xá»‹n)",
                system_note("VÃ­ dá»¥: 'khÃ¡ ráº» nhÆ°ng cáº§n bá»n'"),
            ]),
            "inputs": {}
        }

    return {
        "status": "ok",
        "domain": domain,
        "inputs": {
            "cost_level": cost,
            "precision_importance": precision,
            "durability_importance": durability,
            "speed_importance": speed,
        },
        "missing_fields": [],
        "confidence": 0.7
    }


def _demo_fuzzy_score(inputs: Dict[str, Any], domain: str) -> Dict[str, Any]:
    cost = inputs.get("cost_level", 5)
    prec = inputs.get("precision_importance", 5)
    dura = inputs.get("durability_importance", 5)
    speed = inputs.get("speed_importance", 5)

    score = (10 - cost) * 6 + prec * 7 + dura * 4 + speed * 3
    score = max(0, min(100, score / 2))

    return {
        "engine_version": "demo_v1",
        "domain": domain,
        "decision": {
            "score": round(score, 2),
            "label": "best_match" if score >= 75 else "good" if score >= 60 else "ok" if score >= 40 else "weak",
        },
        "ranked": [],
        "rules_fired": [],
        "breakdown": {"inputs": inputs},
    }
